{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biopython 3: SearchIO and Entrez\n",
    "\n",
    "In this workshop, we will first take a quick look at SearchIO, Biopython's tool for unifying results from various sequence search tools, before exploring the Entrez API utility from NCBI.\n",
    "\n",
    "## SearchIO\n",
    "\n",
    "Biopython provides the [SearchIO package](https://biopython.org/docs/latest/api/Bio.SearchIO.html) for dealing with outputs from various sequence searching utilities, allowing them to be compared directly. Similar to SeqIO and AlignIO, it has capabilities for parsing, reading, writing, and indexing different search results, as well as converting between file types. \n",
    "\n",
    "### Reading and Parsing\n",
    "\n",
    "Parsing and reading also work the same way as previously, where parse returns an iterator, and read simply returns the first item in the file. Note here that each item is a query, not an individual sequence. \n",
    "\n",
    "Let's start with an example of reading and XML result file from a BLAST search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_NON_STICKY_ATTRS', '_QueryResult__alt_hit_ids', '_QueryResult__marker', '__annotations__', '__bool__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_description', '_hit_key_function', '_id', '_items', '_transfer_attrs', 'absorb', 'append', 'blast_id', 'description', 'fragments', 'hit_filter', 'hit_keys', 'hit_map', 'hits', 'hsp_filter', 'hsp_map', 'hsps', 'id', 'index', 'items', 'iterhit_keys', 'iterhits', 'iteritems', 'param_evalue_threshold', 'param_filter', 'param_gap_extend', 'param_gap_open', 'param_score_match', 'param_score_mismatch', 'pop', 'program', 'reference', 'seq_len', 'sort', 'stat_db_len', 'stat_db_num', 'stat_eff_space', 'stat_entropy', 'stat_hsp_len', 'stat_kappa', 'stat_lambda', 'target', 'version']\n",
      "Search 42291 has 100 hits\n",
      "['_NON_STICKY_ATTRS', '__annotations__', '__bool__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_aln_span_get', '_get_coords', '_hit_end_get', '_hit_inter_ranges_get', '_hit_inter_spans_get', '_hit_range_get', '_hit_span_get', '_hit_start_get', '_inter_ranges_get', '_inter_spans_get', '_items', '_query_end_get', '_query_inter_ranges_get', '_query_inter_spans_get', '_query_range_get', '_query_span_get', '_query_start_get', '_str_hsp_header', '_transfer_attrs', '_validate_fragment', 'aln', 'aln_all', 'aln_annotation', 'aln_annotation_all', 'aln_span', 'bitscore', 'bitscore_raw', 'evalue', 'fragment', 'fragments', 'gap_num', 'hit', 'hit_all', 'hit_description', 'hit_end', 'hit_end_all', 'hit_features', 'hit_features_all', 'hit_frame', 'hit_frame_all', 'hit_id', 'hit_inter_ranges', 'hit_inter_spans', 'hit_range', 'hit_range_all', 'hit_span', 'hit_span_all', 'hit_start', 'hit_start_all', 'hit_strand', 'hit_strand_all', 'ident_num', 'is_fragmented', 'molecule_type', 'output_index', 'pos_num', 'query', 'query_all', 'query_description', 'query_end', 'query_end_all', 'query_features', 'query_features_all', 'query_frame', 'query_frame_all', 'query_id', 'query_inter_ranges', 'query_inter_spans', 'query_range', 'query_range_all', 'query_span', 'query_span_all', 'query_start', 'query_start_all', 'query_strand', 'query_strand_all']\n",
      "gi|262205317|ref|NR_030195.1| 4.91307e-23\n",
      "gi|301171311|ref|NR_035856.1| 1.71483e-22\n",
      "gi|270133242|ref|NR_032573.1| 2.54503e-20\n",
      "gi|301171322|ref|NR_035857.1| 8.88303e-20\n",
      "gi|301171322|ref|NR_035857.1| 3.31332e-06\n",
      "gi|301171267|ref|NR_035851.1| 8.88303e-20\n",
      "gi|262205330|ref|NR_030198.1| 8.88303e-20\n",
      "gi|262205330|ref|NR_030198.1| 3.31332e-06\n",
      "gi|262205302|ref|NR_030191.1| 8.88303e-20\n",
      "gi|301171259|ref|NR_035850.1| 3.10048e-19\n",
      "gi|262205451|ref|NR_030222.1| 3.10048e-19\n",
      "gi|301171447|ref|NR_035871.1| 3.77716e-18\n",
      "gi|301171447|ref|NR_035871.1| 0.000140886\n",
      "gi|301171276|ref|NR_035852.1| 3.77716e-18\n",
      "gi|262205290|ref|NR_030188.1| 3.77716e-18\n",
      "gi|301171354|ref|NR_035860.1| 1.31836e-17\n",
      "gi|262205281|ref|NR_030186.1| 1.31836e-17\n",
      "gi|262205298|ref|NR_030190.1| 4.60152e-17\n",
      "gi|262205298|ref|NR_030190.1| 0.000140886\n",
      "gi|301171394|ref|NR_035865.1| 1.60609e-16\n",
      "gi|262205429|ref|NR_030218.1| 1.60609e-16\n",
      "gi|262205423|ref|NR_030217.1| 1.60609e-16\n",
      "gi|301171401|ref|NR_035866.1| 5.6058e-16\n",
      "gi|270133247|ref|NR_032574.1| 5.6058e-16\n",
      "gi|262205309|ref|NR_030193.1| 5.6058e-16\n",
      "gi|270132717|ref|NR_032716.1| 1.95662e-15\n",
      "gi|270132717|ref|NR_032716.1| 0.00171634\n",
      "gi|301171437|ref|NR_035870.1| 6.82927e-15\n",
      "gi|301171437|ref|NR_035870.1| 0.254728\n",
      "gi|270133306|ref|NR_032587.1| 6.82927e-15\n",
      "gi|270133306|ref|NR_032587.1| 9.49283e-07\n",
      "gi|301171428|ref|NR_035869.1| 2.38365e-14\n",
      "gi|301171428|ref|NR_035869.1| 2.71974e-07\n",
      "gi|301171211|ref|NR_035845.1| 2.38365e-14\n",
      "gi|301171153|ref|NR_035838.1| 2.38365e-14\n",
      "gi|301171153|ref|NR_035838.1| 0.0209094\n",
      "gi|301171146|ref|NR_035837.1| 2.38365e-14\n",
      "gi|301171146|ref|NR_035837.1| 0.0209094\n",
      "gi|270133254|ref|NR_032575.1| 2.38365e-14\n",
      "gi|270133254|ref|NR_032575.1| 3.31332e-06\n",
      "gi|262205445|ref|NR_030221.1| 2.38365e-14\n",
      "gi|262205445|ref|NR_030221.1| 0.0209094\n",
      "gi|262205441|ref|NR_030220.1| 2.38365e-14\n",
      "gi|262205441|ref|NR_030220.1| 0.0209094\n",
      "gi|262205325|ref|NR_030197.1| 2.38365e-14\n",
      "gi|262205325|ref|NR_030197.1| 2.71974e-07\n",
      "gi|262205321|ref|NR_030196.1| 2.38365e-14\n",
      "gi|301171236|ref|NR_035848.1| 8.31975e-14\n",
      "gi|301171236|ref|NR_035848.1| 0.000491741\n",
      "gi|262205383|ref|NR_030209.1| 8.31975e-14\n",
      "gi|262205383|ref|NR_030209.1| 0.000491741\n",
      "gi|301171342|ref|NR_035859.1| 2.90388e-13\n",
      "gi|262205265|ref|NR_030183.1| 2.90388e-13\n",
      "gi|301171247|ref|NR_035849.1| 1.01355e-12\n",
      "gi|301171247|ref|NR_035849.1| 2.71974e-07\n",
      "gi|270133223|ref|NR_032569.1| 1.01355e-12\n",
      "gi|262205313|ref|NR_030194.1| 1.01355e-12\n",
      "gi|262205313|ref|NR_030194.1| 2.71974e-07\n",
      "gi|301171225|ref|NR_035847.1| 3.53765e-12\n",
      "gi|301171225|ref|NR_035847.1| 0.000491741\n",
      "gi|270133232|ref|NR_032571.1| 3.53765e-12\n",
      "gi|262205392|ref|NR_030211.1| 3.53765e-12\n",
      "gi|262205392|ref|NR_030211.1| 0.000491741\n",
      "gi|301171300|ref|NR_035855.1| 1.23476e-11\n",
      "gi|301171161|ref|NR_035839.1| 1.23476e-11\n",
      "gi|301171161|ref|NR_035839.1| 0.0729808\n",
      "gi|270133259|ref|NR_032576.1| 1.23476e-11\n",
      "gi|270133259|ref|NR_032576.1| 0.00171634\n",
      "gi|270133218|ref|NR_032568.1| 1.23476e-11\n",
      "gi|270133218|ref|NR_032568.1| 0.00171634\n",
      "gi|270132725|ref|NR_032718.1| 1.23476e-11\n",
      "gi|270132725|ref|NR_032718.1| 0.0729808\n",
      "gi|262205396|ref|NR_030212.1| 1.23476e-11\n",
      "gi|262205396|ref|NR_030212.1| 0.0729808\n",
      "gi|262205294|ref|NR_030189.1| 1.23476e-11\n",
      "gi|301171602|ref|NR_035634.1| 4.30974e-11\n",
      "gi|301171602|ref|NR_035634.1| 0.00599063\n",
      "gi|301171454|ref|NR_035872.1| 4.30974e-11\n",
      "gi|301171333|ref|NR_035858.1| 4.30974e-11\n",
      "gi|301171291|ref|NR_035854.1| 4.30974e-11\n",
      "gi|301171219|ref|NR_035846.1| 4.30974e-11\n",
      "gi|301171219|ref|NR_035846.1| 0.00599063\n",
      "gi|269847477|ref|NR_031696.1| 4.30974e-11\n",
      "gi|262205435|ref|NR_030219.1| 4.30974e-11\n",
      "gi|262205336|ref|NR_030199.1| 4.30974e-11\n",
      "gi|262205336|ref|NR_030199.1| 0.00599063\n",
      "gi|270133264|ref|NR_032577.1| 1.50425e-10\n",
      "gi|269846946|ref|NR_031573.1| 1.50425e-10\n",
      "gi|269846946|ref|NR_031573.1| 0.0209094\n",
      "gi|262205358|ref|NR_030204.1| 1.50425e-10\n",
      "gi|301171206|ref|NR_035844.1| 5.25034e-10\n",
      "gi|301171206|ref|NR_035844.1| 0.00599063\n",
      "gi|301171169|ref|NR_035840.1| 5.25034e-10\n",
      "gi|262205387|ref|NR_030210.1| 5.25034e-10\n",
      "gi|262205387|ref|NR_030210.1| 0.00599063\n",
      "gi|301171381|ref|NR_035863.1| 1.83255e-09\n",
      "gi|270133201|ref|NR_032565.1| 1.83255e-09\n",
      "gi|262205417|ref|NR_030216.1| 1.83255e-09\n",
      "gi|270133214|ref|NR_032567.1| 6.39622e-09\n",
      "gi|262205407|ref|NR_030214.1| 6.39622e-09\n",
      "gi|262205377|ref|NR_030208.1| 6.39622e-09\n",
      "gi|270133311|ref|NR_032588.1| 2.2325e-08\n",
      "gi|270133311|ref|NR_032588.1| 0.0729808\n",
      "gi|270133297|ref|NR_032585.1| 2.2325e-08\n",
      "gi|262205401|ref|NR_030213.1| 2.2325e-08\n",
      "gi|262205401|ref|NR_030213.1| 0.00599063\n",
      "gi|301171372|ref|NR_035862.1| 7.79219e-08\n",
      "gi|301171372|ref|NR_035862.1| 0.00171634\n",
      "gi|262205412|ref|NR_030215.1| 7.79219e-08\n",
      "gi|262205412|ref|NR_030215.1| 0.00171634\n",
      "gi|262205366|ref|NR_030206.1| 7.79219e-08\n",
      "gi|262205366|ref|NR_030206.1| 0.00171634\n",
      "gi|270132721|ref|NR_032717.1| 2.71974e-07\n",
      "gi|270132721|ref|NR_032717.1| 0.889088\n",
      "gi|262205276|ref|NR_030185.1| 9.49283e-07\n",
      "gi|301171363|ref|NR_035861.1| 3.31332e-06\n",
      "gi|270133196|ref|NR_032564.1| 3.31332e-06\n",
      "gi|270133191|ref|NR_032563.1| 3.31332e-06\n",
      "gi|301171387|ref|NR_035864.1| 1.15646e-05\n",
      "gi|262205353|ref|NR_030203.1| 1.15646e-05\n",
      "gi|270133237|ref|NR_032572.1| 0.000140886\n",
      "gi|301171283|ref|NR_035853.1| 0.00171634\n",
      "gi|270133288|ref|NR_032583.1| 0.00171634\n",
      "gi|262205371|ref|NR_030207.1| 0.00171634\n",
      "gi|262205349|ref|NR_030202.1| 0.00171634\n",
      "gi|301171138|ref|NR_035836.1| 0.254728\n",
      "gi|301171409|ref|NR_035867.1| 0.254728\n",
      "gi|301173375|ref|NR_035835.1| 0.254728\n",
      "gi|262205340|ref|NR_030200.1| 0.254728\n",
      "gi|262205285|ref|NR_030187.1| 0.254728\n",
      "gi|262205270|ref|NR_030184.1| 0.254728\n",
      "gi|390332045|ref|XM_776818.2| 0.889088\n",
      "gi|390332043|ref|XM_003723358.1| 0.889088\n",
      "gi|356543101|ref|XM_003539954.1| 0.889088\n",
      "gi|356517317|ref|XM_003527287.1| 0.889088\n",
      "gi|297814701|ref|XM_002875188.1| 0.889088\n",
      "gi|397513516|ref|XM_003827011.1| 3.10322\n"
     ]
    }
   ],
   "source": [
    "# Parse a BLAST XML file\n",
    "\n",
    "from Bio import SearchIO\n",
    "\n",
    "handle = \"searchio-data/blast.xml\"\n",
    "\n",
    "my_result = SearchIO.read(handle = handle, format = \"blast-xml\")\n",
    "print(dir(my_result))\n",
    "\n",
    "print(\"Search {} has {} hits\".format(my_result.id, len(my_result)))\n",
    "\n",
    "print(dir(my_result.hsps[0]))\n",
    "\n",
    "for hsp in my_result.hsps:\n",
    "    print(hsp.hit_id, hsp.evalue) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing and Format Conversion\n",
    "\n",
    "You can also write results files in various file formats. To do this, use the `Bio.SearchIO.write()` function. In the example below, we parse a file in the blast-xml format, and then write its contents to a new file in blast-tab tabular format. \n",
    "\n",
    "```\n",
    "from Bio import SearchIO\n",
    "qresults = SearchIO.parse(handle = 'sample.xml', format = 'blast-xml')\n",
    "SearchIO.write(qresults, handle = 'sample.tab', format = 'blast-tab')\n",
    "```\n",
    "\n",
    "You can also use the `convert()` function to directly convert between file formats without reading/parsing and then writing. The supported formats are below, although not all of the pairs will work for conversion (see [documentation](https://biopython.org/docs/latest/api/Bio.SearchIO.html#Bio.SearchIO.convert) for details).\n",
    "\n",
    "'blast-tab', 'blast-xml', 'blat-psl', 'hmmer3-tab', 'hmmscan3-domtab', 'hmmsearch3-domtab', 'phmmer3-domtab\"\n",
    "\n",
    "The function will return a tuple of four values: the number of QueryResult, Hit, HSP, and HSPFragment objects it writes to the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"searchio-data/blast.xml\"\n",
    "out_file = \"searchio-data/blast_tab.tab\"\n",
    "\n",
    "in_format = \"blast-xml\"\n",
    "out_format = \"blast-tab\"\n",
    "\n",
    "SearchIO.convert(in_file=in_file, in_format=in_format, out_file=out_file, out_format=out_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrez\n",
    "\n",
    "The Entrez system is a collection of [NCBI databases](https://www.ncbi.nlm.nih.gov/guide/all/) ranging from literature to sequences, along with a text search tool for exploring them. You can [search online](https://www.ncbi.nlm.nih.gov/search/) via browser, or through the NCBI's E-utilities API. \n",
    "\n",
    "### Entrez Rules and Etiquette\n",
    "\n",
    "The good news is that Biopython takes care of a lot of the Entrez etiquette for you (limiting the number of queries per second, etc.). However, there are a few things that you must do yourself:\n",
    "\n",
    "1. Always define your Entrez email address (your code will not run without this parameter)\n",
    "2. Specify your tool if you are using Biopython within some larger software package (define `Entrez.tool`)\n",
    "3. Use the session history for large queries\n",
    "4. For large series of requests (>100) try to do this outside of US peak hours\n",
    "\n",
    "### UIDs\n",
    "\n",
    "Every entry in a NCBI database has a UID (unique identifier). This UID will vary depending on the database. For example, PubMed uses PMID while protein records use GI numbers. \n",
    "\n",
    "| Entrez Database    | UID common name | E-utility Database Name |\n",
    "|--------------------|-----------------|-------------------------|\n",
    "| BioProject         | BioProject ID  | bioproject              |\n",
    "| BioSample          | BioSample ID   | biosample               |\n",
    "| Books              | Book ID        | books                   |\n",
    "| Conserved Domains  | PSSM-ID        | cdd                     |\n",
    "| dbGaP              | dbGaP ID       | gap                     |\n",
    "| dbVar              | dbVar ID       | dbvar                   |\n",
    "| Gene               | Gene ID        | gene                    |\n",
    "| Genome             | Genome ID      | genome                  |\n",
    "| GEO Datasets       | GDS ID         | gds                     |\n",
    "| GEO Profiles       | GEO ID         | geoprofiles             |\n",
    "| HomoloGene         | HomoloGene ID  | homologene              |\n",
    "| MeSH               | MeSH ID        | mesh                    |\n",
    "| NCBI C++ Toolkit   | Toolkit ID     | toolkit                 |\n",
    "| NLM Catalog        | NLM Catalog ID | nlmcatalog              |\n",
    "| Nucleotide         | GI number      | nuccore                 |\n",
    "| PopSet             | PopSet ID      | popset                  |\n",
    "| Probe              | Probe ID       | probe                   |\n",
    "| Protein            | GI number      | protein                 |\n",
    "| Protein Clusters   | Protein Cluster ID | proteinclusters      |\n",
    "| PubChem BioAssay   | AID            | pcassay                 |\n",
    "| PubChem Compound   | CID            | pccompound              |\n",
    "| PubChem Substance  | SID            | pcsubstance             |\n",
    "| PubMed             | PMID           | pubmed                  |\n",
    "| PubMed Central     | PMCID          | pmc                     |\n",
    "| SNP                | rs number      | snp                     |\n",
    "| SRA                | SRA ID         | sra                     |\n",
    "| Structure          | MMDB-ID        | structure               |\n",
    "| Taxonomy           | TaxID          | taxonomy                |\n",
    "\n",
    "**Accession.Version vs GI Number**\n",
    "\n",
    "Sequences will have two parallel identifiers given by the NCBI: the GI number and the Accession version. For a full disambiguation, see this [link](https://www.ncbi.nlm.nih.gov/genbank/sequenceids/). \n",
    "\n",
    "### E-Utilities on the Unix Command Line\n",
    "\n",
    "While Biopython gives us nice tools for using the E-utilities withi Python code, they are also available as [command line tools](https://www.ncbi.nlm.nih.gov/books/NBK179288/)\n",
    "\n",
    "### Core Concepts of the E-utilities\n",
    "\n",
    "**What are the E-utilities?**\n",
    "\n",
    "There are nine total E-utilities which perform different tasks with respect to the NCBI databases (from [A General Introduction to the E-utilities](https://www.ncbi.nlm.nih.gov/books/NBK25497/)).\n",
    "\n",
    "1. EInfo (database statistics) eutils.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi\n",
    "\n",
    "    Provides the number of records indexed in each field of a given database, the date of the last update of the database, and the available links from the database to other Entrez databases.\n",
    "\n",
    "2. ESearch (text searches) eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\n",
    "\n",
    "    Responds to a text query with the list of matching UIDs in a given database (for later use in ESummary, EFetch or ELink), along with the term translations of the query.\n",
    "\n",
    "3. EPost (UID uploads) eutils.ncbi.nlm.nih.gov/entrez/eutils/epost.fcgi\n",
    "\n",
    "    Accepts a list of UIDs from a given database, stores the set on the History Server, and responds with a query key and web environment for the uploaded dataset.\n",
    "\n",
    "4. ESummary (document summary downloads) eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\n",
    "\n",
    "    Responds to a list of UIDs from a given database with the corresponding document summaries.\n",
    "\n",
    "5. EFetch (data record downloads) eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\n",
    "\n",
    "    Responds to a list of UIDs in a given database with the corresponding data records in a specified format.\n",
    "\n",
    "6. ELink (Entrez links) eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi\n",
    "\n",
    "    Responds to a list of UIDs in a given database with either a list of related UIDs (and relevancy scores) in the same database or a list of linked UIDs in another Entrez database; checks for the existence of a specified link from a list of one or more UIDs; creates a hyperlink to the primary LinkOut provider for a specific UID and database, or lists LinkOut URLs and attributes for multiple UIDs.\n",
    "\n",
    "7. EGQuery (global query) eutils.ncbi.nlm.nih.gov/entrez/eutils/egquery.fcgi\n",
    "\n",
    "    Responds to a text query with the number of records matching the query in each Entrez database.\n",
    "\n",
    "8. ESpell (spelling suggestions) eutils.ncbi.nlm.nih.gov/entrez/eutils/espell.fcgi\n",
    "\n",
    "    Retrieves spelling suggestions for a text query in a given database.\n",
    "\n",
    "9. ECitMatch (batch citation searching in PubMed) eutils.ncbi.nlm.nih.gov/entrez/eutils/ecitmatch.cgi\n",
    "\n",
    "    Retrieves PubMed IDs (PMIDs) corresponding to a set of input citation strings.\n",
    "\n",
    "## Bio.Entrez Module\n",
    "\n",
    "Biopython gives us a module that allows us to perform these functions inside of a Python script. What it essentially does is to take our arguments, generate the Entrez E-utility URL, send to the NCBI server, and deal with the returned information. The documentation can be found [here](https://biopython.org/docs/latest/api/Bio.Entrez.html). As well as the 9 core functions, the module provides functions for reading and parsing the results.\n",
    "\n",
    "### An Example with EInfo\n",
    "\n",
    "Here we will use the first function, EInfo, to get information on some NCBI databases. The basic routine is as follows:\n",
    "\n",
    "0. Give Entrez your email address.\n",
    "1. Define your handle as the output of the `Entrez.einfo()` function.\n",
    "2. Create a record by \"reading\" the handle using the `Entrez.read()` function. This record will be a nest of Python dictionaries - explore the list by looking at the keys.\n",
    "3. Extract the information you need by calling the specific keys as needed.\n",
    "\n",
    "When given no arguments, `einfo()` returns a list of all valid Entrez databases. You can also specify a database by giving it a `db` (database) variable. Then, it will return the information related to that specific database. There are a couple of other inputs for specifying the output format (JSON is available as well as the default XML) and a version input (which is for the very interested user only - check the documentation for details).\n",
    "\n",
    "First, let's get all of the database information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['DbList'])\n",
      "{'DbList': ['pubmed', 'protein', 'nuccore', 'ipg', 'nucleotide', 'structure', 'genome', 'annotinfo', 'assembly', 'bioproject', 'biosample', 'blastdbinfo', 'books', 'cdd', 'clinvar', 'gap', 'gapplus', 'grasp', 'dbvar', 'gene', 'gds', 'geoprofiles', 'medgen', 'mesh', 'nlmcatalog', 'omim', 'orgtrack', 'pmc', 'popset', 'proteinclusters', 'pcassay', 'protfam', 'pccompound', 'pcsubstance', 'seqannot', 'snp', 'sra', 'taxonomy', 'biocollections', 'gtr']}\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = \"cwarner@rockefeller.edu\"\n",
    "handle = Entrez.einfo() # Get handle with information\n",
    "record = Entrez.read(handle) # Use the Bio parser to turn it into a Python object (dictionary)\n",
    "print(record.keys())\n",
    "print(record)\n",
    "print(len(record['DbList']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can find out more information about the SRA (Sequence Read Archive) database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['DbInfo'])\n",
      "{'DbName': 'gap', 'MenuName': 'dbGaP', 'Description': 'dbGaP Data', 'DbBuild': 'Build230522-0335m.1', 'Count': '363717', 'LastUpdate': '2023/05/22 04:11', 'FieldList': [{'Name': 'ALL', 'FullName': 'All Fields', 'Description': 'All terms from all searchable fields', 'TermCount': '2183077', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'N', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'UID', 'FullName': 'UID', 'Description': 'Unique number assigned to publication', 'TermCount': '0', 'IsDate': 'N', 'IsNumerical': 'Y', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'Y'}, {'Name': 'FILT', 'FullName': 'Filter', 'Description': 'Limits the records', 'TermCount': '23', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DISC', 'FullName': 'Discriminator', 'Description': 'Discriminator', 'TermCount': '10', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ANCE', 'FullName': 'Ancestor', 'Description': 'Ancestor', 'TermCount': '2839', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'BELO', 'FullName': 'Belongs To', 'Description': 'Belongs To', 'TermCount': '2836', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ATTR', 'FullName': 'Attribution', 'Description': 'Attribution', 'TermCount': '16170', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'RTST', 'FullName': 'Is Root Study', 'Description': 'Is Root Study', 'TermCount': '7', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'TLST', 'FullName': 'Is Top-Level Study', 'Description': 'Is Top-Level Study', 'TermCount': '7', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'STID', 'FullName': 'Study ID', 'Description': 'Study ID', 'TermCount': '2836', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'STNM', 'FullName': 'Study Name', 'Description': 'Study Name', 'TermCount': '6491', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DIS', 'FullName': 'Disease', 'Description': 'Disease', 'TermCount': '2646', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'PROJ', 'FullName': 'Project', 'Description': 'Project', 'TermCount': '477', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'GENO', 'FullName': 'Genotype Platform', 'Description': 'Genotype Platform', 'TermCount': '1423', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'SRA', 'FullName': 'Study Has SRA Components', 'Description': 'Study Has SRA components', 'TermCount': '4', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'STUD', 'FullName': 'Study', 'Description': 'Study', 'TermCount': '85745', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'HASV', 'FullName': 'Has Variable', 'Description': 'Has Variable', 'TermCount': '4', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'VRID', 'FullName': 'Variable ID', 'Description': 'Variable ID', 'TermCount': '680333', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'VRNM', 'FullName': 'Variable Name', 'Description': 'Variable Name', 'TermCount': '223739', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'VRDS', 'FullName': 'Variable Description', 'Description': 'Variable Description', 'TermCount': '163304', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'VAR', 'FullName': 'Variable', 'Description': 'Variable', 'TermCount': '1494355', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'HASD', 'FullName': 'Has Document', 'Description': 'Has Document', 'TermCount': '4', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DCID', 'FullName': 'Document ID', 'Description': 'Document ID', 'TermCount': '13281', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DCNM', 'FullName': 'Document Name', 'Description': 'Document Name', 'TermCount': '10738', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DOC', 'FullName': 'Document', 'Description': 'Document', 'TermCount': '764966', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DOCP', 'FullName': 'Document Part', 'Description': 'Document Part', 'TermCount': '123556', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'HASA', 'FullName': 'Has Analysis', 'Description': 'Has Analysis', 'TermCount': '4', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ANID', 'FullName': 'Analysis ID', 'Description': 'Analysis ID', 'TermCount': '8952', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ANNM', 'FullName': 'Analysis Name', 'Description': 'Analysis Name', 'TermCount': '4093', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ANLS', 'FullName': 'Analysis', 'Description': 'Analysis', 'TermCount': '26721', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'HAST', 'FullName': 'Has Dataset', 'Description': 'Has Dataset', 'TermCount': '4', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DSID', 'FullName': 'Dataset ID', 'Description': 'Dataset ID', 'TermCount': '23964', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DSNM', 'FullName': 'Dataset Name', 'Description': 'Dataset Name', 'TermCount': '11508', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DS', 'FullName': 'Dataset', 'Description': 'Dataset', 'TermCount': '65928', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'PX', 'FullName': 'PhenX', 'Description': 'PhenX', 'TermCount': '3637', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'HASP', 'FullName': 'Has PhenX Mapping', 'Description': 'Has PhenX Mapping', 'TermCount': '3', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ARCH', 'FullName': 'Study Archive', 'Description': 'Study Archive', 'TermCount': '1', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'MOLE', 'FullName': 'Molecular Data Type', 'Description': 'Molecular Data Type', 'TermCount': '79', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'PRPH', 'FullName': 'Primary Phenotype in Study', 'Description': 'Primary Phenotype in Study', 'TermCount': '585', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DAC', 'FullName': 'Data Access Committee', 'Description': 'Data Access Committee', 'TermCount': '22', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DESN', 'FullName': 'Study Design', 'Description': 'Study Design', 'TermCount': '15', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'CDER', 'FullName': 'Common Data Element Resource', 'Description': 'Common Data Element Resource (e.g. LOINC, PhenX)', 'TermCount': '3', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'CDET', 'FullName': 'Common Data Element Term', 'Description': 'Common Data Element Term (e.g. PhenX accession)', 'TermCount': '2074', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}], 'LinkList': [{'Name': 'gap_bioproject', 'Menu': 'BioProject Links', 'Description': 'BioProject Links', 'DbTo': 'bioproject'}, {'Name': 'gap_biosample_all', 'Menu': 'BioSample Links', 'Description': 'All related BioSamples', 'DbTo': 'biosample'}, {'Name': 'gap_dbvar', 'Menu': 'dbVar', 'Description': 'Link from dbGaP to dbVar', 'DbTo': 'dbvar'}, {'Name': 'gap_gds', 'Menu': 'GEO DataSets', 'Description': 'GEO DataSet links', 'DbTo': 'gds'}, {'Name': 'gap_gene', 'Menu': 'Gene Links', 'Description': 'Gene Links', 'DbTo': 'gene'}, {'Name': 'gap_medgen', 'Menu': 'MedGen', 'Description': 'MedGen Links', 'DbTo': 'medgen'}, {'Name': 'gap_mesh', 'Menu': 'MeSH', 'Description': 'MeSH links', 'DbTo': 'mesh'}, {'Name': 'gap_pmc', 'Menu': 'PMC Links', 'Description': 'PMC Links', 'DbTo': 'pmc'}, {'Name': 'gap_pubmed', 'Menu': 'PubMed Links', 'Description': 'Related PubMed article', 'DbTo': 'pubmed'}, {'Name': 'gap_snp', 'Menu': 'SNP Links', 'Description': 'SNP Links', 'DbTo': 'snp'}, {'Name': 'gap_sra_all', 'Menu': 'SRA Links', 'Description': 'All related SRA records', 'DbTo': 'sra'}]}\n",
      "[{'Name': 'ALL', 'FullName': 'All Fields', 'Description': 'All terms from all searchable fields', 'TermCount': '2183077', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'N', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'UID', 'FullName': 'UID', 'Description': 'Unique number assigned to publication', 'TermCount': '0', 'IsDate': 'N', 'IsNumerical': 'Y', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'Y'}, {'Name': 'FILT', 'FullName': 'Filter', 'Description': 'Limits the records', 'TermCount': '23', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DISC', 'FullName': 'Discriminator', 'Description': 'Discriminator', 'TermCount': '10', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ANCE', 'FullName': 'Ancestor', 'Description': 'Ancestor', 'TermCount': '2839', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'BELO', 'FullName': 'Belongs To', 'Description': 'Belongs To', 'TermCount': '2836', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ATTR', 'FullName': 'Attribution', 'Description': 'Attribution', 'TermCount': '16170', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'RTST', 'FullName': 'Is Root Study', 'Description': 'Is Root Study', 'TermCount': '7', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'TLST', 'FullName': 'Is Top-Level Study', 'Description': 'Is Top-Level Study', 'TermCount': '7', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'STID', 'FullName': 'Study ID', 'Description': 'Study ID', 'TermCount': '2836', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'STNM', 'FullName': 'Study Name', 'Description': 'Study Name', 'TermCount': '6491', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DIS', 'FullName': 'Disease', 'Description': 'Disease', 'TermCount': '2646', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'PROJ', 'FullName': 'Project', 'Description': 'Project', 'TermCount': '477', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'GENO', 'FullName': 'Genotype Platform', 'Description': 'Genotype Platform', 'TermCount': '1423', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'SRA', 'FullName': 'Study Has SRA Components', 'Description': 'Study Has SRA components', 'TermCount': '4', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'STUD', 'FullName': 'Study', 'Description': 'Study', 'TermCount': '85745', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'HASV', 'FullName': 'Has Variable', 'Description': 'Has Variable', 'TermCount': '4', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'VRID', 'FullName': 'Variable ID', 'Description': 'Variable ID', 'TermCount': '680333', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'VRNM', 'FullName': 'Variable Name', 'Description': 'Variable Name', 'TermCount': '223739', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'VRDS', 'FullName': 'Variable Description', 'Description': 'Variable Description', 'TermCount': '163304', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'VAR', 'FullName': 'Variable', 'Description': 'Variable', 'TermCount': '1494355', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'HASD', 'FullName': 'Has Document', 'Description': 'Has Document', 'TermCount': '4', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DCID', 'FullName': 'Document ID', 'Description': 'Document ID', 'TermCount': '13281', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DCNM', 'FullName': 'Document Name', 'Description': 'Document Name', 'TermCount': '10738', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DOC', 'FullName': 'Document', 'Description': 'Document', 'TermCount': '764966', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DOCP', 'FullName': 'Document Part', 'Description': 'Document Part', 'TermCount': '123556', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'HASA', 'FullName': 'Has Analysis', 'Description': 'Has Analysis', 'TermCount': '4', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ANID', 'FullName': 'Analysis ID', 'Description': 'Analysis ID', 'TermCount': '8952', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ANNM', 'FullName': 'Analysis Name', 'Description': 'Analysis Name', 'TermCount': '4093', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ANLS', 'FullName': 'Analysis', 'Description': 'Analysis', 'TermCount': '26721', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'HAST', 'FullName': 'Has Dataset', 'Description': 'Has Dataset', 'TermCount': '4', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DSID', 'FullName': 'Dataset ID', 'Description': 'Dataset ID', 'TermCount': '23964', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DSNM', 'FullName': 'Dataset Name', 'Description': 'Dataset Name', 'TermCount': '11508', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DS', 'FullName': 'Dataset', 'Description': 'Dataset', 'TermCount': '65928', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'PX', 'FullName': 'PhenX', 'Description': 'PhenX', 'TermCount': '3637', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'HASP', 'FullName': 'Has PhenX Mapping', 'Description': 'Has PhenX Mapping', 'TermCount': '3', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'ARCH', 'FullName': 'Study Archive', 'Description': 'Study Archive', 'TermCount': '1', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'MOLE', 'FullName': 'Molecular Data Type', 'Description': 'Molecular Data Type', 'TermCount': '79', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'PRPH', 'FullName': 'Primary Phenotype in Study', 'Description': 'Primary Phenotype in Study', 'TermCount': '585', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DAC', 'FullName': 'Data Access Committee', 'Description': 'Data Access Committee', 'TermCount': '22', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'DESN', 'FullName': 'Study Design', 'Description': 'Study Design', 'TermCount': '15', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'CDER', 'FullName': 'Common Data Element Resource', 'Description': 'Common Data Element Resource (e.g. LOINC, PhenX)', 'TermCount': '3', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}, {'Name': 'CDET', 'FullName': 'Common Data Element Term', 'Description': 'Common Data Element Term (e.g. PhenX accession)', 'TermCount': '2074', 'IsDate': 'N', 'IsNumerical': 'N', 'SingleToken': 'Y', 'Hierarchy': 'N', 'IsHidden': 'N'}]\n"
     ]
    }
   ],
   "source": [
    "Entrez.email = \"cwarner@rockefeller.edu\"\n",
    "handle = Entrez.einfo(db = \"sra\") # Get handle with information\n",
    "record = Entrez.read(handle) # Change into Python object\n",
    "print(record.keys()) # Print the first \"dictionary layer\"\n",
    "print(record[\"DbInfo\"])\n",
    "print(record[\"DbInfo\"][\"FieldList\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick aside: finding the DTD file\n",
    "\n",
    "Let's do our Einfo search again, but instead of using the `Entrez.read()` function, which translates the XML returned by EInfo to Python dictionaries and lists, read and print it as an XML file so we can examine it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\\n<!DOCTYPE eInfoResult PUBLIC \"-//NLM//DTD einfo 20190110//EN\" \"https://eutils.ncbi.nlm.nih.gov/eutils/dtd/20190110/einfo.dtd\">\\n<eInfoResult>\\n<DbList>\\n\\n\\t<DbName>pubmed</DbName>\\n\\t<DbName>protein</DbName>\\n\\t<DbName>nuccore</DbName>\\n\\t<DbName>ipg</DbName>\\n\\t<DbName>nucleotide</DbName>\\n\\t<DbName>structure</DbName>\\n\\t<DbName>genome</DbName>\\n\\t<DbName>annotinfo</DbName>\\n\\t<DbName>assembly</DbName>\\n\\t<DbName>bioproject</DbName>\\n\\t<DbName>biosample</DbName>\\n\\t<DbName>blastdbinfo</DbName>\\n\\t<DbName>books</DbName>\\n\\t<DbName>cdd</DbName>\\n\\t<DbName>clinvar</DbName>\\n\\t<DbName>gap</DbName>\\n\\t<DbName>gapplus</DbName>\\n\\t<DbName>grasp</DbName>\\n\\t<DbName>dbvar</DbName>\\n\\t<DbName>gene</DbName>\\n\\t<DbName>gds</DbName>\\n\\t<DbName>geoprofiles</DbName>\\n\\t<DbName>medgen</DbName>\\n\\t<DbName>mesh</DbName>\\n\\t<DbName>nlmcatalog</DbName>\\n\\t<DbName>omim</DbName>\\n\\t<DbName>orgtrack</DbName>\\n\\t<DbName>pmc</DbName>\\n\\t<DbName>popset</DbName>\\n\\t<DbName>proteinclusters</DbName>\\n\\t<DbName>pcassay</DbName>\\n\\t<DbName>protfam</DbName>\\n\\t<DbName>pccompound</DbName>\\n\\t<DbName>pcsubstance</DbName>\\n\\t<DbName>seqannot</DbName>\\n\\t<DbName>snp</DbName>\\n\\t<DbName>sra</DbName>\\n\\t<DbName>taxonomy</DbName>\\n\\t<DbName>biocollections</DbName>\\n\\t<DbName>gtr</DbName>\\n</DbList>\\n\\n</eInfoResult>\\n'\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "out_handle = open(\"entrez-data/einfo.xml\", \"w\")\n",
    "Entrez.email = \"cwarner@rockefeller.edu\"\n",
    "handle = Entrez.einfo() # Get handle with information\n",
    "result = handle.read()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the `einfo.xml` results. Note that before the beginning of the results, denoted by `<eInfoResult>`, the header contains information about the file encoding as well as the DTD file used to define the XML data returned. Click on this link and download/open the file. If you ever receive a warning about your DTD file when you use `Entrez.read()`, you will see a link for the updated DTD file in the warning. Biopython will automatically access this new DTD online and continue as usual, but if you want better performance you can update the DTD on your machine (see the Biopython Tutorial document Ch. 9 for complete instructions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example with Genbank Data\n",
    "\n",
    "Here we will use several of the E-utilities to search for genomic data of the RPL16 gene of a prickly pear (opuntia) in the [NCBI Nucleotide Database](https://www.ncbi.nlm.nih.gov/nucleotide/). This will occur in several stages:\n",
    "\n",
    "1. Use EGQuery to find the number of hits for your search terms in the \"nuccore\" database.\n",
    "2. Use ESearch to get the UIDs searching in \"nuccore\" with the desired search terms\n",
    "3. Use EFetch to get the data associated  with those UIDs\n",
    "4. Parse this sequence data and write it to a .gb file\n",
    "5. Check your work by parsing the .gb file\n",
    "\n",
    "In this example, we won't use the History server for simplicity - we will revoisit this example later to show how to use the History server properly. Let's begin by finding the number of results in the \"nuccore\" database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Term', 'eGQueryResult'])\n",
      "[{'DbName': 'pubmed', 'MenuName': 'PubMed', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'pmc', 'MenuName': 'PubMed Central', 'Count': '21', 'Status': 'Ok'}, {'DbName': 'mesh', 'MenuName': 'MeSH', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'books', 'MenuName': 'Books', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'pubmedhealth', 'MenuName': 'PubMed Health', 'Count': 'Error', 'Status': 'Database Error'}, {'DbName': 'omim', 'MenuName': 'OMIM', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'ncbisearch', 'MenuName': 'Site Search', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'nuccore', 'MenuName': 'Nucleotide', 'Count': '115', 'Status': 'Ok'}, {'DbName': 'nucgss', 'MenuName': 'GSS', 'Count': '0', 'Status': 'Ok'}, {'DbName': 'nucest', 'MenuName': 'EST', 'Count': '0', 'Status': 'Ok'}, {'DbName': 'protein', 'MenuName': 'Protein', 'Count': '90', 'Status': 'Ok'}, {'DbName': 'genome', 'MenuName': 'Genome', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'structure', 'MenuName': 'Structure', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'taxonomy', 'MenuName': 'Taxonomy', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'snp', 'MenuName': 'SNP', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'dbvar', 'MenuName': 'dbVar', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'gene', 'MenuName': 'Gene', 'Count': '31', 'Status': 'Ok'}, {'DbName': 'sra', 'MenuName': 'SRA', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'biosystems', 'MenuName': 'BioSystems', 'Count': 'Error', 'Status': 'Database Error'}, {'DbName': 'unigene', 'MenuName': 'UniGene', 'Count': '0', 'Status': 'Ok'}, {'DbName': 'cdd', 'MenuName': 'Conserved Domains', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'clone', 'MenuName': 'Clone', 'Count': '0', 'Status': 'Ok'}, {'DbName': 'popset', 'MenuName': 'PopSet', 'Count': '5', 'Status': 'Ok'}, {'DbName': 'geoprofiles', 'MenuName': 'GEO Profiles', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'gds', 'MenuName': 'GEO DataSets', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'homologene', 'MenuName': 'HomoloGene', 'Count': 'Error', 'Status': 'Database Error'}, {'DbName': 'pccompound', 'MenuName': 'PubChem Compound', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'pcsubstance', 'MenuName': 'PubChem Substance', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'pcassay', 'MenuName': 'PubChem BioAssay', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'nlmcatalog', 'MenuName': 'NLM Catalog', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'probe', 'MenuName': 'Probe', 'Count': '0', 'Status': 'Ok'}, {'DbName': 'gap', 'MenuName': 'dbGaP', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'proteinclusters', 'MenuName': 'Protein Clusters', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'bioproject', 'MenuName': 'BioProject', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'biosample', 'MenuName': 'BioSample', 'Count': '0', 'Status': 'Term or Database is not found'}, {'DbName': 'biocollections', 'MenuName': 'BioCollections', 'Count': '0', 'Status': 'Term or Database is not found'}]\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = \"cwarner@rockefeller.edu\"\n",
    "\n",
    "handle = Entrez.egquery(term=\"Opuntia AND rpl16\") # Search all databases for the specified terms\n",
    "record = Entrez.read(handle) \n",
    "print(record.keys())\n",
    "print(record[\"eGQueryResult\"])\n",
    "\n",
    "for row in record['eGQueryResult']:\n",
    "    if row[\"DbName\"] == \"nuccore\":\n",
    "        print(row[\"Count\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how many results are in the Nucleotide database, we can use ESearch to retrieve the list of UIDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Count', 'RetMax', 'RetStart', 'IdList', 'TranslationSet', 'TranslationStack', 'QueryTranslation'])\n",
      "['2689244941', '2689244853', '2666708278', '2666703263', '2419852361', '2643614054', '2627891212', '2627891124', '2627891047', '2627890961', '2627890885', '2627890802', '2627890718', '2627890636', '2627890548', '2627890460', '2627890382', '2627890305', '2627890228', '2627890152', '2627890068', '2627889984', '2627889900', '2627889817', '2627889740', '2627889653', '2627889560', '2627889470', '2627889380', '2627889278', '2627889193', '2627889118', '2627889035', '2627888952', '2582771976', '2582771888', '2582771811', '2582771725', '2582771649', '2582771566', '2582771482', '2582771400', '2582771312', '2582771241', '2582771153', '2582771075', '2582770998', '2582770921', '2582770845', '2582770761', '2582770677', '2582770593', '2582770510', '2582770433', '2582770349', '2582770274', '2582770192', '2582770117', '2582770042', '2582769959', '2582769885', '2582769808', '2582769733', '2582769650', '2582769567', '2496231309', '2281558632', '2438313908', '2308289420', '2308289413', '2308289406', '2308289399', '2308289392', '2308289385', '2308289378', '2308289371', '2272655797', '2261459663', '1972904692', '1972904685', '1972904678', '1972904671', '1972904664', '1972904657', '1972904650', '1972904643', '1972904636', '1972904629', '1972904622', '1841709044', '377581039', '330887241', '330887240', '330887239', '330887238', '330887237', '330887236', '330887235', '330887233', '330887232', '330887231', '330887228', '330887227', '330887226', '330887225', '330887224', '57240072', '57240071', '6273287', '6273291', '6273290', '6273289', '6273286', '6273285', '6273284']\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "handle = Entrez.esearch(db = \"nuccore\", term = \"Opuntia AND rpl16\", retmax = 200)\n",
    "record = Entrez.read(handle)\n",
    "print(record.keys())\n",
    "id_list = record[\"IdList\"]\n",
    "print(id_list)\n",
    "print(len(id_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use EFetch to get the formatted data, and SeqIO to write them to a data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "handle = Entrez.efetch(db = \"nuccore\", id = id_list, rettype = \"gb\", retmode = \"text\")\n",
    "\n",
    "with open(\"entrez-data/opuntia.gb\", \"w\") as output_handle:\n",
    "    for record in SeqIO.parse(handle = handle, format = \"genbank\"):\n",
    "        SeqIO.write(sequences = record, handle = output_handle, format = \"genbank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check our work, let's parse the new data file we have created and print the first 10 base pairs in each sequence, as well as the sequence ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR885585.1 GACCAAACAG\n",
      "OR885584.1 TTTGTTGAAG\n",
      "NC_085762.1 GCGAACGACG\n",
      "NC_085703.1 ATAAATAATT\n",
      "MZ579523.1 ATAAATAATT\n",
      "OK448352.1 GCGAACGACG\n",
      "NC_083956.1 ACTTAATAGC\n",
      "NC_083955.1 AAAAAGAAAT\n",
      "NC_083954.1 TTAGAAAGAA\n",
      "NC_083953.1 GAAAGGGTAG\n",
      "NC_083952.1 ACAGTAAGAA\n",
      "NC_083951.1 CCAAGTCAAG\n",
      "NC_083950.1 CCAAGTCAAG\n",
      "NC_083949.1 CCAAGTCAAG\n",
      "NC_083948.1 AAAAAGAAAT\n",
      "NC_083947.1 AAAAAGAAAT\n",
      "NC_083946.1 AAAAAGAAAT\n",
      "NC_083945.1 AAGAATTGAA\n",
      "NC_083944.1 TTAGAAAGAA\n",
      "NC_083943.1 TTAGAAAGAA\n",
      "NC_083942.1 CCAAGTCAAG\n",
      "NC_083941.1 CTTGCGCCAA\n",
      "NC_083940.1 CTTGCGCCAA\n",
      "NC_083939.1 CTTGCGCCAA\n",
      "NC_083938.1 AAGAATTGAA\n",
      "NC_083937.1 CTTGCGCCAA\n",
      "NC_083936.1 CCAAGTCAAG\n",
      "NC_083935.1 TTAGAAAGAA\n",
      "NC_083934.1 TTAGAAAGAA\n",
      "NC_083933.1 CTTGCGCCAA\n",
      "NC_083932.1 AAGAATTGAA\n",
      "NC_083931.1 TTAGAAAGAA\n",
      "NC_083930.1 CTTGCGCCAA\n",
      "NC_083929.1 CCAAGTCAAG\n",
      "OQ613407.1 ACTTAATAGC\n",
      "OQ613406.1 AAAAAGAAAT\n",
      "OQ613405.1 TTAGAAAGAA\n",
      "OQ613404.1 GAAAGGGTAG\n",
      "OQ613403.1 ACAGTAAGAA\n",
      "OQ613402.1 CCAAGTCAAG\n",
      "OQ613401.1 CCAAGTCAAG\n",
      "OQ613400.1 CCAAGTCAAG\n",
      "OQ613399.1 AAAAAGAAAT\n",
      "OQ613398.1 GGCGAACGAC\n",
      "OQ613397.1 AAAAAGAAAT\n",
      "OQ613396.1 AAAAAGAAAT\n",
      "OQ613395.1 AAGAATTGAA\n",
      "OQ613394.1 TTAGAAAGAA\n",
      "OQ613393.1 TTAGAAAGAA\n",
      "OQ613392.1 CCAAGTCAAG\n",
      "OQ613391.1 CTTGCGCCAA\n",
      "OQ613390.1 CTTGCGCCAA\n",
      "OQ613389.1 CTTGCGCCAA\n",
      "OQ613388.1 AAGAATTGAA\n",
      "OQ613387.1 CTTGCGCCAA\n",
      "OQ613386.1 CGAGAAAGGG\n",
      "OQ613385.1 CCAAGTCAAG\n",
      "OQ613384.1 TTAGAAAGAA\n",
      "OQ613383.1 TTAGAAAGAA\n",
      "OQ613382.1 CTTGCGCCAA\n",
      "OQ613381.1 ATTTACAGAC\n",
      "OQ613380.1 AAGAATTGAA\n",
      "OQ613379.1 TTAGAAAGAA\n",
      "OQ613378.1 CTTGCGCCAA\n",
      "OQ613377.1 CCAAGTCAAG\n",
      "ON241265.1 CTTAGTGTGT\n",
      "NC_065377.1 ATACTTTCAA\n",
      "OM685013.1 ATGCTTAGTG\n",
      "MZ359277.1 ATGCTTAGTG\n",
      "MZ359273.1 ATGCTTAGTG\n",
      "MZ359269.1 ATGCTTAGTG\n",
      "MZ359265.1 ATGCTTAGTG\n",
      "MZ359261.1 ATGCTTAGTG\n",
      "MZ359257.1 ATGCTTAGTG\n",
      "MZ359253.1 ATGCTTAGTG\n",
      "MZ359249.1 ATGCTTAGTG\n",
      "ON584177.1 ATACTTTCAA\n",
      "MW419517.1 GTAAGAGCCC\n",
      "MT359377.1 ATGCTTAGTG\n",
      "MT359373.1 ATGCTTAGTG\n",
      "MT359369.1 ATGCTTAGTG\n",
      "MT359365.1 ATGCTTAGTG\n",
      "MT359361.1 ATGCTTAGTG\n",
      "MT359357.1 ATGCTTAGTG\n",
      "MT359353.1 ATGCTTAGTG\n",
      "MT359349.1 ATGCTTAGTG\n",
      "MT359345.1 ATGCTTAGTG\n",
      "MT359341.1 ATGCTTAGTG\n",
      "MT359337.1 ATGCTTAGTG\n",
      "MN114084.1 TTCTATAAAC\n",
      "HQ621368.1 AACCCCAAAA\n",
      "HM041482.1 GTGATATACG\n",
      "HM041481.1 TGATATACGA\n",
      "HM041480.1 GCCCATAGTA\n",
      "HM041479.1 GATATACGAA\n",
      "HM041478.1 AAAAGTAAGA\n",
      "HM041477.1 TTGTGNGNCT\n",
      "HM041476.1 GGGCCCNNNA\n",
      "HM041474.1 GAGCCCATAG\n",
      "HM041473.1 CCGNNCNTTG\n",
      "HM041472.1 GTAAGAGCCC\n",
      "HM041469.1 ATATACGAAA\n",
      "HM041468.1 GATATACGAA\n",
      "HM041467.1 GTGATATCGA\n",
      "HM041466.1 GCTGTGATAT\n",
      "HM041465.1 TGATATACGA\n",
      "AY851612.1 CATTAAAGAA\n",
      "AY851611.1 CATTAAAGGA\n",
      "AF191661.1 TATACATTAA\n",
      "AF191665.1 TATACATTAA\n",
      "AF191664.1 TATACATTAA\n",
      "AF191663.1 TATACATTAA\n",
      "AF191660.1 TATACATAAA\n",
      "AF191659.1 TATACATTAA\n",
      "AF191658.1 TATACATTAA\n"
     ]
    }
   ],
   "source": [
    "records = SeqIO.parse(handle = \"entrez-data/opuntia.gb\", format = \"genbank\")\n",
    "for record in records:\n",
    "    print(record.id, record.seq[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the History Feature\n",
    "\n",
    "When we create pipelines of different E-utilities, the best practice is to store the intermediate information on the NCBI History server, rather than on our own devices. To add an item to the History server, we can use the EPost E-utility, or we can set the `usehistory = \"y\"` parameter when using ESearch. Each item in the History server will have two identifying parameters: the WebEnv (cookies string) and an integer Query Key. By invoking these identifiers, we can access our information directly from the server, rather than having to use our own device's memory. Note that we can also combine different records in the History server, which will share a WebEnv but have different Query Keys.\n",
    "\n",
    "In the example below, we will run an ESearch on PubMed, setting `usehistory = \"y\"` so that the results are posted on the server. Then, we will pull the results from the server using EFetch to retrieve the citation information about these items. Without the history, we would have had to define the list of UIDs as a variable in our code, and then call the EFetch function on that list of UIDs. \n",
    "\n",
    "In the code block below, we will run the initial search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Count', 'RetMax', 'RetStart', 'QueryKey', 'WebEnv', 'IdList', 'TranslationSet', 'QueryTranslation', 'ErrorList'])\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = \"cwarner@rockefeller.edu\"\n",
    "\n",
    "handle = Entrez.esearch(db = \"pubmed\", term = \"Opuntia[ORGN]\", reldate = 365, datetype = \"pdat\", usehistory = \"y\")\n",
    "search_results = Entrez.read(handle)\n",
    "print(search_results.keys())\n",
    "\n",
    "count = int(search_results[\"Count\"])\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have performed the search, the results are saved in our History. Now, we can use the EFetch function to refer to these results and get the full citations. We will also download them in batches of 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading records 1 through10\n",
      "Downloading records 11 through20\n",
      "Downloading records 21 through30\n",
      "Downloading records 31 through40\n",
      "Downloading records 41 through50\n",
      "Downloading records 51 through60\n",
      "Downloading records 61 through70\n",
      "Downloading records 71 through80\n",
      "Downloading records 81 through90\n",
      "Downloading records 91 through100\n",
      "Downloading records 101 through110\n",
      "Downloading records 111 through120\n",
      "Downloading records 121 through128\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "out_handle = open(\"entrez-data/opuntia-papers.txt\", \"w\")\n",
    "\n",
    "for start in range(0, count, batch_size):\n",
    "    end = min(count, start + batch_size)\n",
    "    print(\"Downloading records {} through {}\".format(start + 1, end))\n",
    "    fetch_handle = Entrez.efetch(db = \"pubmed\", rettype = \"medline\", retmode = \"text\", retstart = start, retmax = batch_size, webenv = search_results[\"WebEnv\"], query_key = search_results[\"QueryKey\"])\n",
    "\n",
    "    data = fetch_handle.read()\n",
    "    fetch_handle.close()\n",
    "    out_handle.write(data)\n",
    "out_handle.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a MEDLINE formatted file with all 128 citations. We can easily add this to any reference management software. Alternatively, we can use the [`Bio.Medline`](https://biopython.org/docs/latest/api/Bio.Medline.html) module to parse this file and extract additional information. The Bio.Medline package has familiar functions that read and parse MEDLINE formatted text files into Python dictionaries. Below I will show a quick example of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frontiers in veterinary science 2024 ['10.3389/fvets.2024.1359213 [doi]']\n",
      "International journal of systematic and evolutionary microbiology 2024 Feb ['10.1099/ijsem.0.006270 [doi]']\n",
      "Nutrients 2024 Feb 9 ['nu16040499 [pii]', 'nutrients-16-00499 [pii]', '10.3390/nu16040499 [doi]']\n",
      "Foods (Basel, Switzerland) 2024 Feb 15 ['foods13040587 [pii]', 'foods-13-00587 [pii]', '10.3390/foods13040587 [doi]']\n",
      "Food research international (Ottawa, Ont.) 2024 Mar ['S0963-9969(24)00146-7 [pii]', '10.1016/j.foodres.2024.114076 [doi]']\n",
      "Tropical animal health and production 2024 Feb 20 ['10.1007/s11250-024-03928-w [pii]', '10.1007/s11250-024-03928-w [doi]']\n",
      "Scientifica 2024 ['10.1155/2024/7939465 [doi]']\n",
      "PeerJ 2024 ['16861 [pii]', '10.7717/peerj.16861 [doi]']\n",
      "Journal of ethnopharmacology 2024 Feb 11 ['S0378-8741(24)00183-1 [pii]', '10.1016/j.jep.2024.117884 [doi]']\n",
      "Food research international (Ottawa, Ont.) 2024 Mar ['S0963-9969(24)00103-0 [pii]', '10.1016/j.foodres.2024.114033 [doi]']\n",
      "International journal of biological macromolecules 2024 Feb 9 ['S0141-8130(24)00830-4 [pii]', '10.1016/j.ijbiomac.2024.130027 [doi]']\n",
      "Frontiers in plant science 2024 ['10.3389/fpls.2024.1323790 [doi]']\n",
      "Environmental monitoring and assessment 2024 Feb 3 ['10.1007/s10661-024-12406-7 [pii]', '10.1007/s10661-024-12406-7 [doi]']\n",
      "Planta 2024 Jan 31 ['10.1007/s00425-023-04326-6 [pii]', '4326 [pii]', '10.1007/s00425-023-04326-6 [doi]']\n",
      "Microscopy research and technique 2024 Jan 30 ['10.1002/jemt.24500 [doi]']\n",
      "Bulletin of entomological research 2024 Jan 25 ['S000748532300069X [pii]', '10.1017/S000748532300069X [doi]']\n",
      "Plants (Basel, Switzerland) 2024 Jan 11 ['plants13020195 [pii]', 'plants-13-00195 [pii]', '10.3390/plants13020195 [doi]']\n",
      "Scientific reports 2024 Jan 22 ['10.1038/s41598-024-52105-4 [pii]', '52105 [pii]', '10.1038/s41598-024-52105-4 [doi]']\n",
      "Chemistry & biodiversity 2024 Jan 22 ['10.1002/cbdv.202301890 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 Nov 22 ['foods12234213 [pii]', 'foods-12-04213 [pii]', '10.3390/foods12234213 [doi]']\n",
      "Journal of traditional and complementary medicine 2024 Jan ['S2225-4110(23)00084-6 [pii]', '10.1016/j.jtcme.2023.08.001 [doi]']\n",
      "Plant foods for human nutrition (Dordrecht, Netherlands) 2024 Mar ['10.1007/s11130-023-01137-8 [pii]', '1137 [pii]', '10.1007/s11130-023-01137-8 [doi]']\n",
      "Plants (Basel, Switzerland) 2023 Dec 31 ['plants13010121 [pii]', 'plants-13-00121 [pii]', '10.3390/plants13010121 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 Dec 25 ['foods13010078 [pii]', 'foods-13-00078 [pii]', '10.3390/foods13010078 [doi]']\n",
      "International journal of biological macromolecules 2024 Feb ['S0141-8130(24)00110-7 [pii]', '10.1016/j.ijbiomac.2024.129307 [doi]']\n",
      "Plant disease 2024 Jan 8 ['10.1094/PDIS-07-23-1344-PDN [doi]']\n",
      "Fish physiology and biochemistry 2024 Jan 5 ['10.1007/s10695-023-01289-z [pii]', '10.1007/s10695-023-01289-z [doi]']\n",
      "Polymers 2023 Dec 15 ['polym15244720 [pii]', 'polymers-15-04720 [pii]', '10.3390/polym15244720 [doi]']\n",
      "Polymers 2023 Dec 7 ['polym15244640 [pii]', 'polymers-15-04640 [pii]', '10.3390/polym15244640 [doi]']\n",
      "Pharmaceuticals (Basel, Switzerland) 2023 Nov 30 ['ph16121671 [pii]', 'pharmaceuticals-16-01671 [pii]', '10.3390/ph16121671 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 Dec 7 ['foods12244403 [pii]', 'foods-12-04403 [pii]', '10.3390/foods12244403 [doi]']\n",
      "Biotechnology and applied biochemistry 2023 Dec 19 ['10.1002/bab.2543 [doi]']\n",
      "Acta biomaterialia 2024 Jan 15 ['S1742-7061(23)00708-0 [pii]', '10.1016/j.actbio.2023.12.005 [doi]']\n",
      "Scientific reports 2023 Dec 8 ['10.1038/s41598-023-48976-8 [pii]', '48976 [pii]', '10.1038/s41598-023-48976-8 [doi]']\n",
      "International journal of biological macromolecules 2024 Feb ['S0141-8130(23)05273-X [pii]', '10.1016/j.ijbiomac.2023.128374 [doi]']\n",
      "Natural product research 2023 Dec 3 ['10.1080/14786419.2023.2284253 [doi]']\n",
      "Trends in plant science 2023 Nov 30 ['S1360-1385(23)00366-7 [pii]', '10.1016/j.tplants.2023.11.007 [doi]']\n",
      "International journal of biological macromolecules 2024 Jan ['S0141-8130(23)05402-8 [pii]', '10.1016/j.ijbiomac.2023.128503 [doi]']\n",
      "Plant disease 2023 Nov 30 ['10.1094/PDIS-08-23-1575-PDN [doi]']\n",
      "Heliyon 2023 Nov ['S2405-8440(23)09148-X [pii]', 'e21940 [pii]', '10.1016/j.heliyon.2023.e21940 [doi]']\n",
      "Scientific reports 2023 Nov 24 ['10.1038/s41598-023-48152-y [pii]', '48152 [pii]', '10.1038/s41598-023-48152-y [doi]']\n",
      "La Clinica terapeutica 2023 Nov-Dec ['10.7417/CT.2023.2483 [doi]']\n",
      "International journal of experimental pathology 2024 Feb ['IEP12498 [pii]', '10.1111/iep.12498 [doi]']\n",
      "Fitoterapia 2024 Jan ['S0367-326X(23)00327-1 [pii]', '10.1016/j.fitote.2023.105752 [doi]']\n",
      "Gut and liver 2023 Nov 15 ['gnl230446 [pii]', 'gnl-17-6-954 [pii]', '10.5009/gnl230446 [doi]']\n",
      "Polymers 2023 Nov 1 ['polym15214295 [pii]', 'polymers-15-04295 [pii]', '10.3390/polym15214295 [doi]']\n",
      "Journal of dairy science 2023 Nov 7 ['S0022-0302(23)00737-3 [pii]', '10.3168/jds.2023-23847 [doi]']\n",
      "Natural product research 2023 Nov 8 ['10.1080/14786419.2023.2272031 [doi]']\n",
      "Natural product research 2023 Nov 1 ['10.1080/14786419.2023.2272781 [doi]']\n",
      "The Libyan journal of medicine 2023 Dec ['10.1080/19932820.2023.2275417 [doi]']\n",
      "Insects 2023 Oct 13 ['insects14100811 [pii]', 'insects-14-00811 [pii]', '10.3390/insects14100811 [doi]']\n",
      "Biology 2023 Oct 16 ['biology12101339 [pii]', 'biology-12-01339 [pii]', '10.3390/biology12101339 [doi]']\n",
      "TheScientificWorldJournal 2023 ['10.1155/2023/6670648 [doi]']\n",
      "Tropical medicine and health 2023 Oct 24 ['10.1186/s41182-023-00550-8 [pii]', '550 [pii]', '10.1186/s41182-023-00550-8 [doi]']\n",
      "Frontiers in microbiology 2023 ['10.3389/fmicb.2023.1273940 [doi]']\n",
      "Plant foods for human nutrition (Dordrecht, Netherlands) 2023 Dec ['10.1007/s11130-023-01113-2 [pii]', '10.1007/s11130-023-01113-2 [doi]']\n",
      "Frontiers in plant science 2023 ['10.3389/fpls.2023.1236123 [doi]']\n",
      "PloS one 2023 ['PONE-D-23-05787 [pii]', '10.1371/journal.pone.0289709 [doi]']\n",
      "Heliyon 2023 Sep ['S2405-8440(23)07204-3 [pii]', 'e19996 [pii]', '10.1016/j.heliyon.2023.e19996 [doi]']\n",
      "Food research international (Ottawa, Ont.) 2023 Nov ['S0963-9969(23)00933-X [pii]', '10.1016/j.foodres.2023.113388 [doi]']\n",
      "Physiology & behavior 2023 Dec 1 ['S0031-9384(23)00285-8 [pii]', '10.1016/j.physbeh.2023.114360 [doi]']\n",
      "Plants (Basel, Switzerland) 2023 Sep 17 ['plants12183287 [pii]', 'plants-12-03287 [pii]', '10.3390/plants12183287 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 Sep 19 ['foods12183479 [pii]', 'foods-12-03479 [pii]', '10.3390/foods12183479 [doi]']\n",
      "Gels (Basel, Switzerland) 2023 Sep 4 ['gels9090716 [pii]', 'gels-09-00716 [pii]', '10.3390/gels9090716 [doi]']\n",
      "ACS omega 2023 Sep 19 ['10.1021/acsomega.3c02735 [doi]']\n",
      "Environmental monitoring and assessment 2023 Aug 31 ['10.1007/s10661-023-11766-w [pii]', '10.1007/s10661-023-11766-w [doi]']\n",
      "International journal of biological macromolecules 2023 Dec 1 ['S0141-8130(23)03352-4 [pii]', '10.1016/j.ijbiomac.2023.126456 [doi]']\n",
      "Plants (Basel, Switzerland) 2023 Aug 9 ['plants12162907 [pii]', 'plants-12-02907 [pii]', '10.3390/plants12162907 [doi]']\n",
      "Materials (Basel, Switzerland) 2023 Aug 10 ['ma16165571 [pii]', 'materials-16-05571 [pii]', '10.3390/ma16165571 [doi]']\n",
      "Biomedicines 2023 Aug 2 ['biomedicines11082173 [pii]', 'biomedicines-11-02173 [pii]', '10.3390/biomedicines11082173 [doi]']\n",
      "Frontiers in microbiology 2023 ['10.3389/fmicb.2023.1232323 [doi]']\n",
      "Brazilian journal of biology = Revista brasleira de biologia 2023 ['S1519-69842023000100834 [pii]', '10.1590/1519-6984.274016 [doi]']\n",
      "Nutrients 2023 Aug 7 ['nu15153495 [pii]', 'nutrients-15-03495 [pii]', '10.3390/nu15153495 [doi]']\n",
      "Plants (Basel, Switzerland) 2023 Jul 25 ['plants12152758 [pii]', 'plants-12-02758 [pii]', '10.3390/plants12152758 [doi]']\n",
      "Archives of microbiology 2023 Aug 7 ['10.1007/s00203-023-03646-1 [pii]', '10.1007/s00203-023-03646-1 [doi]']\n",
      "Tropical animal health and production 2023 Aug 4 ['10.1007/s11250-023-03698-x [pii]', '10.1007/s11250-023-03698-x [doi]']\n",
      "Journal of applied microbiology 2023 Aug 1 ['7236862 [pii]', '10.1093/jambio/lxad174 [doi]']\n",
      "Plants (Basel, Switzerland) 2023 Jul 18 ['plants12142677 [pii]', 'plants-12-02677 [pii]', '10.3390/plants12142677 [doi]']\n",
      "Antioxidants (Basel, Switzerland) 2023 Jun 23 ['antiox12071329 [pii]', 'antioxidants-12-01329 [pii]', '10.3390/antiox12071329 [doi]']\n",
      "Environmental science and pollution research international 2023 Aug ['10.1007/s11356-023-28470-4 [pii]', '10.1007/s11356-023-28470-4 [doi]']\n",
      "Annals of botany 2023 Nov 25 ['7226531 [pii]', 'mcad098 [pii]', '10.1093/aob/mcad098 [doi]']\n",
      "Nutrients 2023 Jun 29 ['nu15132962 [pii]', 'nutrients-15-02962 [pii]', '10.3390/nu15132962 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 Jun 27 ['foods12132494 [pii]', 'foods-12-02494 [pii]', '10.3390/foods12132494 [doi]']\n",
      "Food chemistry 2023 Dec 1 ['S0308-8146(23)01374-2 [pii]', '10.1016/j.foodchem.2023.136756 [doi]']\n",
      "Evidence-based complementary and alternative medicine : eCAM 2023 ['10.1155/2023/7837615 [doi]']\n",
      "Current microbiology 2023 Jul 3 ['10.1007/s00284-023-03368-z [pii]', '3368 [pii]', '10.1007/s00284-023-03368-z [doi]']\n",
      "Antioxidants (Basel, Switzerland) 2023 May 29 ['antiox12061174 [pii]', 'antioxidants-12-01174 [pii]', '10.3390/antiox12061174 [doi]']\n",
      "International journal of biological macromolecules 2023 Aug 1 ['S0141-8130(23)02444-3 [pii]', '10.1016/j.ijbiomac.2023.125550 [doi]']\n",
      "Talanta 2023 Dec 1 ['S0039-9140(23)00535-0 [pii]', '10.1016/j.talanta.2023.124784 [doi]']\n",
      "Molecules (Basel, Switzerland) 2023 May 31 ['molecules28114451 [pii]', 'molecules-28-04451 [pii]', '10.3390/molecules28114451 [doi]']\n",
      "International journal of molecular sciences 2023 Jun 2 ['ijms24119669 [pii]', 'ijms-24-09669 [pii]', '10.3390/ijms24119669 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 Jun 1 ['foods12112243 [pii]', 'foods-12-02243 [pii]', '10.3390/foods12112243 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 May 23 ['foods12112096 [pii]', 'foods-12-02096 [pii]', '10.3390/foods12112096 [doi]']\n",
      "Ultrasonics sonochemistry 2023 Jul ['S1350-4177(23)00177-3 [pii]', '106465 [pii]', '10.1016/j.ultsonch.2023.106465 [doi]']\n",
      "Ultrasonics sonochemistry 2023 Jul ['S1350-4177(23)00171-2 [pii]', '106459 [pii]', '10.1016/j.ultsonch.2023.106459 [doi]']\n",
      "Annals of botany 2023 Nov 25 ['7187259 [pii]', 'mcad070 [pii]', '10.1093/aob/mcad070 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 May 21 ['foods12102071 [pii]', 'foods-12-02071 [pii]', '10.3390/foods12102071 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 May 17 ['foods12102024 [pii]', 'foods-12-02024 [pii]', '10.3390/foods12102024 [doi]']\n",
      "Journal of functional biomaterials 2023 May 1 ['jfb14050252 [pii]', 'jfb-14-00252 [pii]', '10.3390/jfb14050252 [doi]']\n",
      "Molecules (Basel, Switzerland) 2023 May 8 ['molecules28093953 [pii]', 'molecules-28-03953 [pii]', '10.3390/molecules28093953 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 Apr 27 ['foods12091811 [pii]', 'foods-12-01811 [pii]', '10.3390/foods12091811 [doi]']\n",
      "Primates; journal of primatology 2023 Jul ['10.1007/s10329-023-01060-1 [pii]', '1060 [pii]', '10.1007/s10329-023-01060-1 [doi]']\n",
      "Ecology and evolution 2023 May ['ECE310050 [pii]', '10.1002/ece3.10050 [doi]']\n",
      "Nutrients 2023 Apr 18 ['nu15081947 [pii]', 'nutrients-15-01947 [pii]', '10.3390/nu15081947 [doi]']\n",
      "Journal of fungi (Basel, Switzerland) 2023 Mar 24 ['jof9040405 [pii]', 'jof-09-00405 [pii]', '10.3390/jof9040405 [doi]']\n",
      "Veterinary medicine international 2023 ['10.1155/2023/6248890 [doi]']\n",
      "Journal of ethnopharmacology 2023 Aug 10 ['S0378-8741(23)00358-6 [pii]', '10.1016/j.jep.2023.116490 [doi]']\n",
      "Food science & nutrition 2023 Apr ['FSN33226 [pii]', '10.1002/fsn3.3226 [doi]']\n",
      "Plants (Basel, Switzerland) 2023 Apr 3 ['plants12071537 [pii]', 'plants-12-01537 [pii]', '10.3390/plants12071537 [doi]']\n",
      "Plants (Basel, Switzerland) 2023 Mar 30 ['plants12071512 [pii]', 'plants-12-01512 [pii]', '10.3390/plants12071512 [doi]']\n",
      "Foods (Basel, Switzerland) 2023 Mar 29 ['foods12071465 [pii]', 'foods-12-01465 [pii]', '10.3390/foods12071465 [doi]']\n",
      "Heliyon 2023 Apr ['S2405-8440(23)02134-5 [pii]', 'e14927 [pii]', '10.1016/j.heliyon.2023.e14927 [doi]']\n",
      "Analytical biochemistry 2023 Jun 1 ['S0003-2697(23)00104-5 [pii]', '10.1016/j.ab.2023.115139 [doi]']\n",
      "Journal of the science of food and agriculture 2023 Aug 30 ['10.1002/jsfa.12605 [doi]']\n",
      "Food chemistry 2023 Aug 30 ['S0308-8146(23)00625-8 [pii]', '10.1016/j.foodchem.2023.136007 [doi]']\n",
      "Environmental monitoring and assessment 2023 Mar 21 ['10.1007/s10661-023-11095-y [pii]', '10.1007/s10661-023-11095-y [doi]']\n",
      "Food & function 2023 Apr 3 ['10.1039/d2fo03834j [doi]']\n",
      "Ecology 2023 May ['10.1002/ecy.4037 [doi]']\n",
      "Scientific reports 2023 Mar 14 ['10.1038/s41598-023-31423-z [pii]', '31423 [pii]', '10.1038/s41598-023-31423-z [doi]']\n",
      "Protoplasma 2023 Sep ['10.1007/s00709-023-01846-6 [pii]', '1846 [pii]', '10.1007/s00709-023-01846-6 [doi]']\n",
      "Journal of plant research 2023 May ['10.1007/s10265-023-01449-5 [pii]', '1449 [pii]', '10.1007/s10265-023-01449-5 [doi]']\n",
      "Neotropical entomology 2023 Jun ['10.1007/s13744-022-01018-w [pii]', '10.1007/s13744-022-01018-w [doi]']\n",
      "Food chemistry 2023 Jun 1 ['S0308-8146(22)03331-3 [pii]', '10.1016/j.foodchem.2022.135369 [doi]']\n",
      "Natural product research 2023 Aug-Sep ['10.1080/14786419.2022.2124984 [doi]']\n",
      "Natural product research 2023 Jun ['10.1080/14786419.2022.2119966 [doi]']\n",
      "Natural product research 2023 May ['10.1080/14786419.2022.2106481 [doi]']\n",
      "Biotechnology and applied biochemistry 2023 Apr ['10.1002/bab.2382 [doi]']\n",
      "Archives of insect biochemistry and physiology 2023 May ['10.1002/arch.21872 [doi]']\n"
     ]
    }
   ],
   "source": [
    "from Bio import Medline\n",
    "\n",
    "handle = open(\"entrez-data/opuntia-papers.txt\", \"r\")\n",
    "\n",
    "for record in Medline.parse(handle):\n",
    "    print(record['JT'], record['DP'], record['AID'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Revisiting our GenBank Search\n",
    "\n",
    "With this in mind, let's also revisit our Opuntia sequence search and do things the \"right\" way using the History server. First, let's redo our search but this time using `usehistory = \"y\"`. Note that we no longer have to deal with the awkward problem of \"retmax\" since the results are being stored on the server, and we are not actually retrieving the list of UIDs here! All we need is the \"Count\", which is the total number of results rather than the number of UIDs returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCID_65ef23ef25842c72a56cfb44\n",
      "1\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = \"cwarner@rockefeller.edu\"\n",
    "\n",
    "handle = Entrez.esearch(db = \"nuccore\", term = \"Opuntia AND rpl16\", usehistory = \"y\")\n",
    "search_results = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "webenv = search_results[\"WebEnv\"]\n",
    "query_key = search_results[\"QueryKey\"]\n",
    "count = int(search_results[\"Count\"])\n",
    "\n",
    "print(webenv)\n",
    "print(query_key)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the search saved in the History, we can download the results in batches (best practice). This time, let's write them to a file in FASTA format. For all of the available retrieval modes (defined by the `retmode` variable), see this [table](https://www.ncbi.nlm.nih.gov/books/NBK25499/table/chapter4.T._valid_values_of__retmode_and/?report=objectonly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading records 1 through 10\n",
      "Downloading records 11 through 20\n",
      "Downloading records 21 through 30\n",
      "Downloading records 31 through 40\n",
      "Downloading records 41 through 50\n",
      "Downloading records 51 through 60\n",
      "Downloading records 61 through 70\n",
      "Downloading records 71 through 80\n",
      "Downloading records 81 through 90\n",
      "Downloading records 91 through 100\n",
      "Downloading records 101 through 110\n",
      "Downloading records 111 through 115\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "out_handle = open(\"entrez-data/opuntia.fasta\", \"w\")\n",
    "\n",
    "for start in range(0, count, batch_size):\n",
    "    end = min(count, start + batch_size)\n",
    "    print(\"Downloading records {} through {}\".format(start + 1, end))\n",
    "    fetch_handle = Entrez.efetch(db = \"nuccore\", rettype = \"fasta\", retmode = \"text\", retstart = start, retmax = batch_size, webenv = webenv, query_key = query_key)\n",
    "    data = fetch_handle.read()\n",
    "    fetch_handle.close()\n",
    "    out_handle.write(data)\n",
    "out_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's parse the data and see that it is the same as what we got before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR885585.1 GACCAAACAG\n",
      "OR885584.1 TTTGTTGAAG\n",
      "NC_085762.1 GCGAACGACG\n",
      "NC_085703.1 ATAAATAATT\n",
      "MZ579523.1 ATAAATAATT\n",
      "OK448352.1 GCGAACGACG\n",
      "NC_083956.1 ACTTAATAGC\n",
      "NC_083955.1 AAAAAGAAAT\n",
      "NC_083954.1 TTAGAAAGAA\n",
      "NC_083953.1 GAAAGGGTAG\n",
      "NC_083952.1 ACAGTAAGAA\n",
      "NC_083951.1 CCAAGTCAAG\n",
      "NC_083950.1 CCAAGTCAAG\n",
      "NC_083949.1 CCAAGTCAAG\n",
      "NC_083948.1 AAAAAGAAAT\n",
      "NC_083947.1 AAAAAGAAAT\n",
      "NC_083946.1 AAAAAGAAAT\n",
      "NC_083945.1 AAGAATTGAA\n",
      "NC_083944.1 TTAGAAAGAA\n",
      "NC_083943.1 TTAGAAAGAA\n",
      "NC_083942.1 CCAAGTCAAG\n",
      "NC_083941.1 CTTGCGCCAA\n",
      "NC_083940.1 CTTGCGCCAA\n",
      "NC_083939.1 CTTGCGCCAA\n",
      "NC_083938.1 AAGAATTGAA\n",
      "NC_083937.1 CTTGCGCCAA\n",
      "NC_083936.1 CCAAGTCAAG\n",
      "NC_083935.1 TTAGAAAGAA\n",
      "NC_083934.1 TTAGAAAGAA\n",
      "NC_083933.1 CTTGCGCCAA\n",
      "NC_083932.1 AAGAATTGAA\n",
      "NC_083931.1 TTAGAAAGAA\n",
      "NC_083930.1 CTTGCGCCAA\n",
      "NC_083929.1 CCAAGTCAAG\n",
      "OQ613407.1 ACTTAATAGC\n",
      "OQ613406.1 AAAAAGAAAT\n",
      "OQ613405.1 TTAGAAAGAA\n",
      "OQ613404.1 GAAAGGGTAG\n",
      "OQ613403.1 ACAGTAAGAA\n",
      "OQ613402.1 CCAAGTCAAG\n",
      "OQ613401.1 CCAAGTCAAG\n",
      "OQ613400.1 CCAAGTCAAG\n",
      "OQ613399.1 AAAAAGAAAT\n",
      "OQ613398.1 GGCGAACGAC\n",
      "OQ613397.1 AAAAAGAAAT\n",
      "OQ613396.1 AAAAAGAAAT\n",
      "OQ613395.1 AAGAATTGAA\n",
      "OQ613394.1 TTAGAAAGAA\n",
      "OQ613393.1 TTAGAAAGAA\n",
      "OQ613392.1 CCAAGTCAAG\n",
      "OQ613391.1 CTTGCGCCAA\n",
      "OQ613390.1 CTTGCGCCAA\n",
      "OQ613389.1 CTTGCGCCAA\n",
      "OQ613388.1 AAGAATTGAA\n",
      "OQ613387.1 CTTGCGCCAA\n",
      "OQ613386.1 CGAGAAAGGG\n",
      "OQ613385.1 CCAAGTCAAG\n",
      "OQ613384.1 TTAGAAAGAA\n",
      "OQ613383.1 TTAGAAAGAA\n",
      "OQ613382.1 CTTGCGCCAA\n",
      "OQ613381.1 ATTTACAGAC\n",
      "OQ613380.1 AAGAATTGAA\n",
      "OQ613379.1 TTAGAAAGAA\n",
      "OQ613378.1 CTTGCGCCAA\n",
      "OQ613377.1 CCAAGTCAAG\n",
      "ON241265.1 CTTAGTGTGT\n",
      "NC_065377.1 ATACTTTCAA\n",
      "OM685013.1 ATGCTTAGTG\n",
      "MZ359277.1 ATGCTTAGTG\n",
      "MZ359273.1 ATGCTTAGTG\n",
      "MZ359269.1 ATGCTTAGTG\n",
      "MZ359265.1 ATGCTTAGTG\n",
      "MZ359261.1 ATGCTTAGTG\n",
      "MZ359257.1 ATGCTTAGTG\n",
      "MZ359253.1 ATGCTTAGTG\n",
      "MZ359249.1 ATGCTTAGTG\n",
      "ON584177.1 ATACTTTCAA\n",
      "MW419517.1 GTAAGAGCCC\n",
      "MT359377.1 ATGCTTAGTG\n",
      "MT359373.1 ATGCTTAGTG\n",
      "MT359369.1 ATGCTTAGTG\n",
      "MT359365.1 ATGCTTAGTG\n",
      "MT359361.1 ATGCTTAGTG\n",
      "MT359357.1 ATGCTTAGTG\n",
      "MT359353.1 ATGCTTAGTG\n",
      "MT359349.1 ATGCTTAGTG\n",
      "MT359345.1 ATGCTTAGTG\n",
      "MT359341.1 ATGCTTAGTG\n",
      "MT359337.1 ATGCTTAGTG\n",
      "MN114084.1 TTCTATAAAC\n",
      "HQ621368.1 AACCCCAAAA\n",
      "HM041482.1 GTGATATACG\n",
      "HM041481.1 TGATATACGA\n",
      "HM041480.1 GCCCATAGTA\n",
      "HM041479.1 GATATACGAA\n",
      "HM041478.1 AAAAGTAAGA\n",
      "HM041477.1 TTGTGNGNCT\n",
      "HM041476.1 GGGCCCNNNA\n",
      "HM041474.1 GAGCCCATAG\n",
      "HM041473.1 CCGNNCNTTG\n",
      "HM041472.1 GTAAGAGCCC\n",
      "HM041469.1 ATATACGAAA\n",
      "HM041468.1 GATATACGAA\n",
      "HM041467.1 GTGATATCGA\n",
      "HM041466.1 GCTGTGATAT\n",
      "HM041465.1 TGATATACGA\n",
      "AY851612.1 CATTAAAGAA\n",
      "AY851611.1 CATTAAAGGA\n",
      "AF191661.1 TATACATTAA\n",
      "AF191665.1 TATACATTAA\n",
      "AF191664.1 TATACATTAA\n",
      "AF191663.1 TATACATTAA\n",
      "AF191660.1 TATACATAAA\n",
      "AF191659.1 TATACATTAA\n",
      "AF191658.1 TATACATTAA\n"
     ]
    }
   ],
   "source": [
    "records = SeqIO.parse(handle = \"entrez-data/opuntia.fasta\", format = \"fasta\")\n",
    "for record in records:\n",
    "    print(record.id, record.seq[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example with ELink\n",
    "\n",
    "Let's use a different E-utility this time: ELink. ELink allows you to search through NCBI databases for related items. This can be used to find associated publictions by terms, data, or other publications, find related datasets, and more. The full documentation can be found in the Entrez Help document as well as in the Biopython Tutorial (Section 9.7).\n",
    "\n",
    "ESearch has 3 required arguments: \n",
    "\n",
    "- `db`, the database to look for connections in\n",
    "- `dbfrom`, the datbase of the original item we want to find connections to\n",
    "- `id`, the list of UIDs in `dbfrom`\n",
    "\n",
    "In the example below, we will search for a term in the taxonomy database using ESearch, and then ue the UID found as an input to ELink to find relted publications in PubMed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Count': '1', 'RetMax': '1', 'RetStart': '0', 'IdList': ['9709'], 'TranslationSet': [], 'TranslationStack': [{'Term': 'phocidae[All Names]', 'Field': 'All Names', 'Count': '1', 'Explode': 'N'}, 'GROUP'], 'QueryTranslation': 'phocidae[All Names]'}\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = \"cwarner@rockefeller.edu\"\n",
    "\n",
    "handle = Entrez.esearch(db = \"taxonomy\", term = \"phocidae\")\n",
    "results = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "print(results)\n",
    "\n",
    "id_list = results[\"IdList\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use ELink to find related items in PubMed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = Entrez.elink(db = \"pubmed\", dbfrom = \"taxonomy\", id = id_list, usehistory = \"y\")\n",
    "search_results = Entrez.read(handle)\n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's print out some of the PubMed results and extract some of the information, such as Journals and DOIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pubmed taxonomy_pubmed_majr 1144\n",
      "pubmed taxonomy_pubmed_mesh 416\n"
     ]
    }
   ],
   "source": [
    "for linksetdb in search_results[0][\"LinkSetDb\"]:\n",
    "    print(linksetdb[\"DbTo\"], linksetdb[\"LinkName\"], len(linksetdb[\"Link\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting It All Together & Final Thoughts\n",
    "\n",
    "### Dealing with Large Data: Reading vs Parsing\n",
    "\n",
    "As we have seen throughout the Biopython module, when dealing with large data files it is better to parse them rather than reading them. Rather than creating one Python object for your entire data file (in this case an XML file), the `Entrez.parse()` function allows you to read XML records one-by-one. In this workshop, we have not be dealing with large data files and will simply use the `Entrez.read()` function. Note that one result from an E-utility can't be parsed because it counts as one \"item\". This is intended for other types of XML data from NCBI.\n",
    "\n",
    "### Building Python Functions with E-utilities\n",
    "\n",
    "All of the code we wrote previously could be easily worked into Python functions. For example, you could define a function that searches PubMed for a given search term and then generates a citation file all in one step (or a similar scheme for retrieving data files).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links and Documentation\n",
    "\n",
    "* [Bio.SearchIO Documentation](https://biopython.org/docs/latest/api/Bio.SearchIO.html)\n",
    "* [Bio.Entrez Documentation](https://biopython.org/docs/latest/api/Bio.Entrez.html)\n",
    "* [Entrez Help](https://www.ncbi.nlm.nih.gov/books/NBK3837/)\n",
    "* [Table of Entrez Databases and UIDs](https://www.ncbi.nlm.nih.gov/books/NBK25497/table/chapter2.T._entrez_unique_identifiers_ui/)\n",
    "* [Values of retmode and rettype for EFetch](https://www.ncbi.nlm.nih.gov/books/NBK25499/table/chapter4.T._valid_values_of__retmode_and/?report=objectonly)\n",
    "* [Table of ELinks](https://eutils.ncbi.nlm.nih.gov/entrez/query/static/entrezlinks.html)\n",
    "\n",
    "## Credits and Inspiration\n",
    "\n",
    "* [Biopython Tutorial and Cookbook](https://biopython.org/DIST/docs/tutorial/Tutorial.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biopython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
